---
format: 
  live-html:
    css: "style-webr.css"
webr:
  cell-options:
    fig-width: 5
    fig-height: 3
    autorun: false
    completion: true
    edit: true
    eval: true
    include: true
    persist: true
    warning: false
  packages: 
    - tidyverse
    - palmerpenguins  # penguins dataset
    - nycflights13    # data on flights from NY airport
    - janitor
    - Lahman          # basketball data
    - usethis
    - ggridges        # ridgline plots (extension of ggplot)
    - rio             # import data from other software
    - forcats # factor
    - downlit
    - xml2
    - babynames     # baby names dataset - strings
    - gt            # gt tables
---
{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

## Transform

## Logical vectors

## Numbers

## Strings

### Creating strings, escapes and raw strings

```{r}
#| warning: false
#| message: false
#| include: false

# install.packages(
#   c("arrow", "babynames", "curl", "duckdb", "gapminder",
#     "ggrepel", "ggridges", "ggthemes", "hexbin", "janitor", "Lahman",
#     "leaflet", "maps", "nycflights13", "openxlsx", "palmerpenguins",
#     "repurrrsive", "tidymodels", "writexl")
# )
library(tidyverse)
conflicted::conflicts_prefer(
  dplyr::filter(),
  dplyr::lag(),
)
library(babynames)
```

Use `'` or `"` to create strings, `"` is recommended per tidyverse style guide except when there are multiple quotes in a string. To include a literal single or double quote, use `\` to escape `\'` and `\"`. `\` is also used to escape special characters like new line `\n` or tab `\t`, `\\` for backslash itself. See `?Quotes` for all special characters.

```{r}
double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'"
backslash <- "\\"
```

:::: {.callout-note}

The printed representation of strings is different from the string itself. The printed string object shows the escapes. To see the row content of a string, use `str_vew()`.

```{r}
x <- c(single_quote, double_quote, backslash)
x
str_view(x)
```

:::

When you habve many escapes `\` in a string, so called [leaning toothpick syndrome](https://en.wikipedia.org/wiki/Leaning_toothpick_syndrome), you can use **raw strings**.

```{r}
tricky <- "double_quote <- \"\\\"\" # or '\"'
single_quote <- '\\'' # or \"'\""
str_view(tricky)
```

```{r}
tricky_raw <- r"(double_quote <- "\"" # or '"'
single_quote <- '\'' # or "'")"
str_view(tricky_raw)
```

A raw string starts with `r"(` and ends with `)"`, and everything in between is taken literally, including quotes and backslashes. If the string `)"`, you can use `r"[ ]"`, or `r"{ }"`, or inserting any number of dashes to make the opening and closing delimiters unique, e.g. `r"--( )--"` or `r"---( )---"`.

:::: {.callout-note}

`str_view()` uses curly braces for tabs `{\t}` to make them more visible.

```{webr}
x <- c("one\ntwo", "one\ttwo", "\u00b5", "\U0001f604")
x
str_view(x)
```

:::

### Exercises

:::: {.panel-tabset}

#### Question 1

```
Create strings that contain the following values:

  1. He said "That's amazing!"

  2. \a\b\c\d

  3. \\\\\\
```

#### Solution

```{webr}
# 1. He said "That's amazing!"
str1 <- "He said \"That's amazing!\""
str1
str1 <- 'He said "That\'s amazing!"'
str1
```

```{webr}
# 2. \a\b\c\d
str2 <- "\\a\\b\\c\\d"
str2
str2 <- r"(\a\b\c\d)"
str2
```

```{webr}
# 3. \\\\\\
str3 <- r"(\\\\\\)"
```

:::

:::: {.panel-tabset}

#### Question 2

```
Create the string in your R session and print it. 
What happens to the special “\u00a0”? 
How does str_view() display it? 
Can you do a little googling to figure out what this special character is?

x <- "This\u00a0is\u00a0tricky"
```

#### Solution

```{webr}
# 1. He said "That's amazing!"
x <- "This\u00a0is\u00a0tricky"
x
str_view(x)
```

#### Hint

```
`\u00a0` is a non-breaking space character.
```

:::

### strings from data: str_c(), str_glue(), str_flatten()

### str_c()

`str_c()`:

1. takes any number of vectors and returns a character vector similar to `base::paste0()`.

```{webr}
str_c("x", "y", "z")
str_c("Hello ", c("John", "Susan"))
```

2. obeys tidyverse rule for recycling and propagating missing values `NA`: is designed to be used with `mutate()`.

```{webr}
#| autorun: true 
df <- tibble(name = c("Flora", "David", "Terra", NA))
```

```{webr}
df |> 
  mutate(greeting = str_c("Hi ", name, "!"))
```

3. if missing values should display in another way, use `coalesce()` inside or outside `str_c()`.

```{webr}
coalesce(c("one", "two", NA), "good") # coalesce replaces NA with "good"

df |>
  mutate(
    greeting1 = str_c("Hi ", coalesce(name, "you"), "!"),
    greeting2 = coalesce(str_c("Hi ", name, "!"), "Hi!")
  )
```

### str_glue()

`str_glue()` from the {glue} package allows the use of `{}` to mix fixed and variable strings. This improves readability compared to `str_c()`. But `str_glue()` does not propagate missing values `NA` by default, so you may need to use `coalesce()`.

To escape `{` or `}`, use double braces `{{` or `}}`.

```{webr}
df |> 
  mutate(greeting = str_glue("Hi {name}!"))

df |> 
  mutate(greeting = str_glue("}}{{Hi {name}!}}"))

```


### str_flatten()

- `str_c()` and `str_glue()` work well with `mutate()` because their output is the same length as their inputs.
- `str_flatten()` takes a character vector, combines each element of the vector and returns a single string: it works well with `summarize()`.
  
```{webr}
ft <- str_flatten(c("x", "y", "z"))
str(ft)
ct <- str_c(c("x", "y", "z"))
str(ct)
gl <- str_glue("x", "y", "z")
str(gl)

str_flatten(c("x", "y", "z"), ", ")

str_flatten(c("x", "y", "z"), ", ", last = ", and ")
```

:::: {.details open="true"}
:::: {.summary}
**str_flatten()**
:::

```r
str_flatten(
  string, 
  collapse = "", 
  last = NULL, 
  na.rm = FALSE
)

str_flatten_comma(
  string,
  last = NULL,
  na.rm = FALSE
)
```
:::

An exemple of how `str_flatten()` works well with `summarise()`:

```{webr}
#| autorun: true
df <- tribble(
  ~ name, ~ fruit,
  "Carmen", "banana",
  "Carmen", "apple",
  "Marvin", "nectarine",
  "Terence", "cantaloupe",
  "Terence", "papaya",
  "Terence", "mandarin"
)
```

```{webr}
df |> 
  summarise(
    fruits = str_flatten(fruit, ", "),
    .by = name
  )
  
df |>
  group_by(name) |>
  summarise(
    fruits = str_flatten(fruit, ", ")
  )
df |>
  group_by(name) |>
  summarise(
    fruits = str_flatten_comma(fruit)
  )
```

### Exercises

:::: {.panel-tabset}

#### Question 1

```
Compare and contrast the results of paste0() with str_c() for the following inputs:
```

```{r}
#| eval: false
str_c("hi ", NA)
str_c(letters[1:2], letters[1:3])
```

#### Solution

```{webr}

str_c("hi ", NA) # concatenates "hi " with NA to produce NA
paste0("hi ", NA) # paste0 "hi" with NA to produce "hiNA"
paste("hi ", NA)  # paste "hi" with NA to produce "hi NA" with a (default) space

str_c(letters[1:2], letters[1:3])
paste0(letters[1:2], letters[1:4])
```

:::

:::: {.panel-tabset}

#### Question 2

````
What’s the difference between `paste()` and `paste0()?` How can you recreate the equivalent of `paste()` with `str_c()`?
````

#### Solution

```{webr}
# Try here!

```

#### Hint

```
paste (..., sep = " ", collapse = NULL, recycle0 = FALSE)

paste0(...,            collapse = NULL, recycle0 = FALSE)
```

:::

:::: {.panel-tabset}

#### Question 3

````
Convert the following expressions from str_c() to str_glue() or vice versa:
a. `str_c("The price of ", food, " is ", price)`
b. `str_glue("I'm {age} years old and live in {country}")`
c. `str_c("\\section{", title, "}")`
````

#### Solution

```{webr}
# a.
str_glue("The price of {food} is {price}")

# b.
str_c("I'm ", age, " years old and live in ", country)

# c.
str_glue("\\section{{{title}}}")

```

:::

###  data from strings: 

If multiple variables are crammed into a single string, you can use four tydr functions to separate them:

- `separate_longer_delim(col, delim)` : creates new rows -- `delim` splits string with delimiter e.g. `", "` or `" "`

- `separate_longer_position(col, width)` : creates new rows -- `position` splits string at specified widths e.g. `c(3, 2)`

- `separate_wider_delim(col, delim, names)` : creates new columns

- `separate_wider_position(col, widths)` : creates new columns

>[!Tips]
> Look at these too:
> `str_split()`, `str_split_fixed()`, `str_extract()`, and `str_match()`.
>

### separate_longer_delim() and separate_longer_position()

```{webr}
df1 <- tibble(x = c("a,b,c", "d,e", "f"))
df1 |> 
  separate_longer_delim(x, delim = ",")
```

```{webr}
df2 <- tibble(x = c("1211", "131", "21"))
df2 |> 
  separate_longer_position(x, width = 1)
```

### separate_wider_delim() and separate_wider_position()

Here `x` object is made up of a code, an edition, and a year separated by `"."`.

```{webr}
df3 <- tibble(x = c("a10.1.2022", "b10.2.2011", "e15.1.2015"))
df3
df3 |> 
  separate_wider_delim(
    x,
    delim = ".",
    names = c("code", "edition", "year")
  )
```

If a specific is not useful, you can use an `NA` to omit it from the results:

```{webr}
df3 |> 
  separate_wider_delim(
    x,
    delim = ".",
    names = c("code", NA, "year")
  )
```

`separate_wider_position()` works a little differently: its arguments are **the string**, **widths** (of each column). `widths = c(name=value, name=value, etc)` **a named integer vector**, where _the name gives the name of the new column_, and _the value is the number of characters it occupies_. You can omit values from the output by not naming them:

```{webr}
df4 <- tibble(x = c("202215TX", "202122LA", "202325CA")) 
df4 |> 
  separate_wider_position(
    x,
    widths = c(year = 4, age = 2, state = 2)
  )
```


### Diagnosing widening problems

`separate_wider_delim()` requires a fixed and known set of columns. If some rows don't have the expected (equal) number of pieces, the function issues an error. To resolve the issue, the function has 2 arguments `too_few` and `too_many`. 

```{webr}
df <- tibble(a = c("1-1-1", "1-1-2", "1-3", "1-3-2", "1"))
df

df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z")
  )
```

The error gives even suggestion on how to proceed: debug or silence the error message.

```{webr}
df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_few = "debug"
  )

debug <- df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_few = "debug"
  )
```

The "debug" mode helps identify the input that succeeded (`_ok` is TRUE) and those that failed (`_ok` is FALSE). `_pieces` column shows how many pieces were found compared to the expected number of pieces (length of `names` argument). `_remainder`is more useful when there are too many pieces. `_ok` can be used to filter the rows that failed vs. succeeded.

```{webr}
debug |> filter(!a_ok)
debug |> filter(a_ok)
```

You may want to fill the missing pieces with `NA`: `too_few = align_start` fills missing pieces at the end with `NA`, while `too_few = align_end` fills missing pieces at the start with `NA`.

```{webr}
df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_few = "align_start"
  )
```

The same principles apply when you have too many pieces: `too_many = "debug"` allows the input with extra/additional pieces in `_remainder` column.

```{webr}
df <- tibble(a = c("1-1-1", "1-1-2", "1-3-5-6", "1-3-2", "1-3-5-7-9"))

df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z")
  )
```

```{webr}
df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_many = "debug"
  )
```

You can either 'drop' the extra pieces with `too_many = "drop"` or "merge" them into the last column with `too_many = "merge"`.

```{webr}
df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_many = "drop"
  )

df |> 
  separate_wider_delim(
    a,
    delim = "-",
    names = c("x", "y", "z"),
    too_many = "merge"
  )
```

### Letters

:::: {.callout-note title="Aims" icon=false}

- Work with individual letters in a string.
- Find the length of a string: `str_length()`
- extract substrings: `str_sub()`
- Handle long strings in plots and tables.

:::

### str_length()

- `str_length()` counts the number of characters (incl. spaces) in a string.
- Use with `count()` to find the distribtion of lengths of strings, e.g. baby names in the US.
- Use with `filter()` to find the shortest or longest strings/names.
  
```{webr}
str_length(c("a", "R for Data Science", NA))
```  

```{webr}
babynames |>
  count(length = str_length(name), wt = n)

babynames |> 
  filter(str_length(name) == 15) |> 
  count(name, wt = n, sort = TRUE)
```

### Subsetting with str_sub()

`str_sub(string, start, end)` extracts substrings from `string`, starting at position `start` and ending at position `end`. Negative values for `start` or `end` count backwards from the end of the string. The `start` and `end` arguments are inclusive so the length of the returned substring is `end - start + 1`.

```{webr}
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)

str_sub(x, -3, -1)
```

If the string is too short, it returns as many characters as possible.

```{webr}
str_sub("ab", 1, 5)
```

### Exercises

:::: {.panel-tabset}

#### Question 1



When computing the distribution of the length of babynames, why did we use `wt = n`?


#### Solution

```{webr}
# Try and learn count() and its wt argument.
```

:::

:::: {.panel-tabset}

#### Question 2

Use `str_length()` and `str_sub()` to extract the middle letter from each baby name. What will you do if the string has an even number of characters?


```{webr}
head(babynames)

babynames |> 
 mutate(
#  tot_length = str_length())
  even_names = str_sub(
    name, 
    start = (str_length(name) / 2) + 0.5,
    end = (str_length(name) / 2) + 0.5
  )
 )
```

:::

:::: {.panel-tabset}

#### Question 3

Are there any major trends in the **length** of babynames over time? What about the popularity of first and last letters?

#### Solution

Length of babynames over time:

```{webr}
babynames |>
  group_by(year) |>
  summarise(
    mean_length_babyname = mean(str_length(name))
  ) |> 
  ggplot(aes(x = year, y = mean_length_babyname)) +
  geom_line()

```

Popularity of first letters over time:

```{webr}
letters <- babynames |> 
 mutate(
  first_letter = str_sub(
    name, 1, 1),
  last_letter = str_sub(name, -1, -1)
 )
first_trend <- letters |>
  group_by(year, first_letter) |> 
  summarise(
    count = sum(n, na.rm = TRUE), 
    .groups = "drop"
  ) |> 
    mutate(prop = count / sum(count)) |> 
    ungroup()
top_first_letters <- letters |> 
  count(first_letter, name = "total", wt = n) |>
  arrange(desc(total)) |> 
  slice_head(n = 10) |> 
  pull(first_letter)

first_trend |> 
  filter(first_letter %in% top_first_letters) |> 
  ggplot(aes(x = year, y = prop, color = first_letter)) +
  geom_line()

```

#### Hint

```{webr}
# Try and learn count() and its wt argument.
```

:::

### Non-English text

Regarding non-English text, there are challenges one may face: **endoding**, **letter variations**, and **locale-dependent functions**.

```{r}
charToRaw("Hadley")
```

Each of these hexadecimal numbers represents one letter. The mapping from hexadecimal numbers to letters is called an encoding. In this case the encoding is called ASCII. There are two different encoding in Europe, Latin1 and Latin2. But fortunately, today there is one standard that is supported almost everywhere: UTF-8 that can code about every character used by humans incl. symbols and emoji. {readr} uses UTF-8 everywhere. UTF-8 is good default but it will fail for data produced by older older systems. When this happens your strings will look weird.

```{webr}
#| eval: false
x1 <- "text\nEl Ni\xf1o was particularly bad this year"
read_csv(x1)$text

x2 <- "text\n\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"
read_csv(x2)$text
```

To read this, specify the encoding with `locale()` argument of `read_csv()`.

```{webr}
read_csv(x1, locale = locale(encoding = "Latin1"))$text

read_csv(x2, locale = locale(encoding = "Shift-JIS"))$text
```

To find the encoding, use `readr::guess_encoding()` to help figure out. You may need to try a few before finding the right one.

To learn more on encoding, see https://kunststube.net/encoding/.

### Letter variations

Working with languages with accents is challenging as `str_length()` and `str_sub()` may not behave as expected. 

```{webr}
u <- c("\u00fc", "u\u0308")
str_view(u)
```

But both strings differ in length and their first character:

```{webr}
str_length(u)

str_sub(u, 1, 1)
```

Also, comparing these strings with `==` shows they are different, with `str_equal()` recognizes them as equal.

```{webr}
u[[ 1 ]] == u[[ 2 ]]

str_equal(u[[ 1 ]] , u[[ 2 ]])
```

### Locale-dependent functions

There are some stringr functions that behave differently depending on the locale. A locale is specified by a lower-case language abbreviation, optionally followed by a `_`  and an upper-case region identifier, e.g. `"en_US"` for English as used in the United States, or `"fr_FR"` for French as used in France.

To see a list of supported locale in stringr, call `stringi::stri_locale_list()`.

Base R automatically uses the system locale. Base R string functions will do what you expect in your language but your code may behave differently if you share them to someone from another country. To avoid this stringr functions default to the `"en"` locale and require you to specify the `locale` to override it. 

There are only two set of functions where the local matter: **changing case** and **sorting**. 

Ex. Turkish has two different versions of the letter "i": a dotted version "i" and a dotless version "ı". Since they two different letters, they are capitalised differently:

```{webr}
str_to_upper(c("i", "ı"))
str_to_upper(c("i", "ı"), locale = "tr")
```

Another example is sorting: sorting depends on the order of the alphabet which is not the same in every language. In Czech, "ch" is considered a single letter that comes after "h".

```{webr}
str_sort(c("a", "c", "ch", "h", "z"))
str_sort(c("a", "c", "ch", "h", "z"), locale = "cs")
```

`dplyr::arrange()` has `locale` argument.

## Regex

### Introduction to regex

:::: {.callout-note title="Aims" icon=false}

- Basic regex and most useful stringr functions.
- Seven new topic: escaping, anchoring, character classes, shorthand classes, quantifiers, precedence, and grouping.
- Flags that allow to tweak the operation of regex.
- survey of other places in the tidyverse and base R where one might use regexes.

:::

```{webr}
#| autorun: true
library(tidyverse)
library(babynames)
```

The chapter will use regex functions from stringr and tidyr as well as data from the babynames package, and three character vector from stringr: `fruit` (contains the names of 80 fruits), `words` (contains 900 common English words), and `sentences` (contains 720 short sentences).

###  Pattern basics

We will use `str_view()` to see how regex patterns work. We will use it with its second argument, a regex.

str_view() will show only the elements of the string that match, surrounding it with `<>`.

```{webr}
str_view(fruit, "berry")
```

Letters and numbers match exactly and are called **literal characters**. Punctuation characters like `.`, `(`, `)`, `\`, `|`, `?`, `*`, `+`, `{`, `}`, `^`, and `$` have special meaning in regex and are called **metacharacters**:

:::: {.callout-tip title="Metacharacters"}

- `.`: matches any character except a new line.
- `^` and `$`: **anchors** to matches the start and end of a string.
- `[]`: defines **character classes** matches any character inside the brackets. `^` at the start of a character class negates it, matching any character not in the brackets.
- `|`: defines **alternation**, and means "or" (pick one or more alternative patterns).
- `?`, `*`, `+`, `{}`: quantifiers that specify how many times the preceding element should be matched`:
  + `?` : matches 0 or 1 time (makes a pattern optional).
  + `*` : matches 0 or more times.
  + `+` : matches 1 or more times.
  + `{}` : matches a specific number of times.

:::

Quantifiers:

```{webr}
# ab? matches an "a", optionally followed by a "b".
str_view(c("a", "ab", "abb"), "ab?")

# ab+ matches an "a", followed by at least one "b".
str_view(c("a", "ab", "abb"), "ab+")

# ab* matches an "a", followed by any number of "b"s.
str_view(c("a", "ab", "abb"), "ab*")
```

Character classes:

```{webr}
str_view(words, "[aeiou]x[aeiou]")

str_view(words, "[^aeiou]y[^aeiou]")
```

Alternation:

```{webr}
str_view(fruit, "apple|mellon|nut")
str_view(fruit, "aa|ee|ii|oo|uu")
```

### str_detect() detects matches

`str_detect()`:
- returns a logical vector that indicates whether or not each string contains a match to the pattern.
- returns a logical vector of the same length as the input vector.
- it pairs well with `filter()`.
- it can be used with `summerise()`by pairing with sum() and mean(): `sum(str_dectect(x, pattern))` to show the number of observations that match the pattern and `mean(str_detect(x, pattern))` shows the proportion of observations that match the pattern.

```{webr}
str_detect(c("a", "b", "c"), "[aeiou]")
```

This code finds all the most popular names containing a lower-case “x”:
```{webr}
babynames |> 
  filter(str_detect(name, "x")) |> 
  count(name, wt = n, sort = TRUE)
```

The proportion of baby names4 that contain “x”, broken down by year:

```{webr}
babynames |> 
  group_by(year) |> 
  summarize(prop_x = mean(str_detect(name, "x"))) |> 
  ggplot(aes(x = year, y = prop_x)) + 
  geom_line()
```

Two other functions related to `str_detect()` are `str_which()` and `str_subset()`: `str_which()` return an integer vector giving the positions of the strings that match the pattern, while `str_subset()` returns a character vector containing only the strings that match the pattern.

### str_count() counts matches

`str_count()` tells how many matches there are in each string.

```{r}
x <- c("apple", "banana", "pear")
str_count(x, "p")
```

Each match starts at the end of the previous match, so regex matches never overlap.

```{r}
str_count("abababa", "aba")

str_view("abababa", "aba")
```

`str_count()` can be used with `mutate()`. In the exemple below, count the number of vowels and consonants in each name.

```{r}
babynames |>
  count(name) |>
  mutate(
    vowels = str_count(name, "[aeiou]"),
    consonants = str_count(name, "[^aeiou]")
  )
```

The code found only 2 vowels in `Aaban` instead of 3 because regex are case-sensitive. To make them case-insensitive:
- Add upper case to character classs: `str_count(name, "[aeiouAEIOU]")`
- Use the argument `ignore_case = TRUE`: `str_count(name, "[aeiou]", ignore_case = TRUE)`.
- Use `str_to_lower()` or `str_to_upper()` to convert the strings to lower or upper case before counting: `str_count(str_to_lower(name), "[aeiou]")`.

```{r}
#| eval: false
babynames |>
  count(name) |>
  mutate(
    name = str_to_lower(name),
    vowels = str_count(name, "[aeiou]"),
    consonants = str_count(name, "[^aeiou]")
  )
```

### str_replace() and str_replace_all() modifie matches

`str_replace()` replaces the first match, and `str_replace_all()` replaces all matches.

```{r}
x <- c("apple", "pear", "banana")
str_replace_all(x, "[aeiou]", "-")

str_replace(x, "[aeiou]", "-")
```

`str_remove()` and `str_remove_all()` are shortcuts of `str_replace(x, pattern, "")` and `str_replace_all(x, pattern, "")`.

### separate_wider_regex() extracts from columns into new columns

The family of `separate_wider_*()`functions live in tidyr because they operate on columns of data frames rather than on individual vectors.

Below are some data derived from `babynames` where we have the name, gender, and age of a bunch of people in a weird format:

```{r}
df <- tribble(
  ~str              ,
  "<Sheryl>-F_34"   ,
  "<Kisha>-F_45"    ,
  "<Brandon>-N_33"  ,
  "<Sharon>-F_38"   ,
  "<Penny>-F_58"    ,
  "<Justin>-M_41"   ,
  "<Patricia>-F_84" ,
)
```

Using `separate_wider_regex()`, we can extract different parts of `df$str` into new columns:

```{r}
df |>
  separate_wider_regex(
    str,
    pattern = c(
      "<",
      name = "[A-Za-z]+",
      ">-",
      gender = "[NMF]",
      "_",
      age = "[0-9]+"
    )
  )
```

If the match fails, use `too_few = debug` to diagnose the problem.

### Exercises

:::: {.panel-tabset}

#### Question 1

What baby name has the most vowels? What name has the highest proportion of vowels? (Hint: what is the denominator?)

#### Solution

```{webr}
# Try here
```

#### Hint

```r
babynames |>
  count(name) |> 
  mutate(
    name = str_to_lower(name),
    n_vowels = str_count(name, "[ aeiou ]"),
    total_letters = str_count(name, "[a-z]"),
    prop_vowel = n_vowels/total_letters
  ) |> 
    arrange(desc(n_vowels)) |>          #<1>
    arrange(desc(prop_vowel))           #<2>
```

1. Show most vowels at the top: 15
2. Show highest proportion of vowels at the top: 0.85 (after 1 those with only vowels)

:::

:::: {.panel-tabset}

#### Question 2

Replace all forward slashes in "a/b/c/d/e" with backslashes. What happens if you attempt to undo the transformation by replacing all backslashes with forward slashes? (We’ll discuss the problem very soon.)

#### Solution

```{webr}
str_replace_all("a/b/c/d/e", "\\/", "/")

```

#### Hint

It seems like, slash in the `pattern` argument needs to be escaped with `\\`, but `replacement` argument we do not need to escape. 

:::


:::: {.panel-tabset}

#### Question 3

```
Implement a simple version of str_to_lower() using str_replace_all().
```

#### Solution

```{webr}
# Try
#babynames |> 
#  count(name) |> 
#  mutate(
#    new_lower = str_replace_all(name, "^(A-Z)", "\\1")
#  )
```

#### Hint

```r
babynames |> 
  count(name) |> 
  mutate(
   vers = str_replace_all(name, "^[A-Z]?", "")
  )
```

:::

:::: {.panel-tabset}

#### Question 4

```
Create a regular expression that will match telephone numbers as commonly written in your country.
```

#### Solution

```{webr}
# Try and learn count() and its wt argument.
```

#### Hint

```r

"^(\+46|0)(\s?-?\(?\d{1,3}\)?)([\s-]?\d{2,3}){2,3}$"

^(\+46|0)                         #<1>
(\s?-?\(?\d{1,3}\)?)              #<2>
([\s-]?\d{2,3}){2,3}$             #<3>
```

1. Start of string `^` with  `+46` or `0046` or `0`. Obs. `\+` to escape `+` and `|` alternation.
2. `\s?` matches any whitespace (space, tab); `?` makes it optional. `-?` optional dash. `\(?` literal `(` that is optional. `\d` matches a 0-9 digit; quantifier `{1,3}` specifies 1 to 3 digits. `\)?` optional `)`.
3. `([\s-]?\d{2,3}){2,3}$` matches the second part of the phone number, which is 2 to 3 digits, and is repeated 2 to 3 times. Meaning that it matches 2-3 groups of 2-3 preceded by an optional space or dash. `$` asserts position at the end of the string.

`()` specify capturing groups. Regex can match even without `()` to only get the full match with `str_match()`. But with `()` `str_match()` returns a matrix where the first column is the complete match, and subsequent columns are the capturing groups.

:::

### Pattern details

### Escaping metacharacters

Because `\` is used as an escape symbol in strings, you need to use double backslashes `\\` to escape metacharacters in regex patterns.

```{r}
dot <- "\\."

str_view(dot)

str_view(c("abc", "a.c", "bef"), "a\\.c")
```

To match a literal backslash `\`, you need to escape it creating  regex `\\`. To create this regex, you need to use a string which also needs to escape each backslash, resulting in four backslashes `\\\\` to match a single backslash.

:::: {.callout-important}
In this book, we’ll usually write regular expression without quotes, like `\.`. If we need to emphasize what you’ll actually type, we’ll surround it with quotes and add extra escapes, like `"\\."`.
:::

```{r}
x <- "a\\b"
str_view(x)

str_view(x, "\\\\")
```

Raw strings can be easier to use:

```{r}
str_view(x, r"{\\}")
```

Another alternative when trying to literal `.`, `$`, `*`, `|`, `+`, `?`, `(`, `)`, `{`, `}` is to use a character class: `[.]`, `[$]`, `[|]`, etc.

```{r}
str_view(c("abc", "a.c", "a*c", "a c"), "a[.]c")

str_view(c("abc", "a.c", "a*c", "a c"), ".[*]c")
```

### Anchors: ^ and $

```{r}
head(fruit)
str_view(fruit, "^a")

str_view(fruit, "a$")
```

You can match the boundary between words with `\b`. `\bsum\b` matches `sum()` but not `summary()` or `summarize()`.

```{r}
x <- c("summary(x)", "summarize(df)", "rowsum(x)", "sum(x)")
str_view(x, "sum")

str_view(x, "\\bsum\\b")
```

When used alone, anchors will produce a zero-width match:

```{r}
str_view("abc", c("$", "^", "\\b"))
```

See what happens when you replace a standalone anchor:

```{r}
str_replace_all("abc", c("$", "^", "\\b"), "--")
```

### Character classes

Character classs or character set allows to match any character from a set of characters defined in `[]`. 

:::: {.callout-tip title="Character classes"}

- `[abc]` matches any of the letters a, b, or c, 
- `[^abc]` matches any character except a, b, or c
- `-` defines a range such as `[a-z]` matches any lower-case letter and `[0-9]` matches any digit.
- `\` escapes special characters, such as `[\^\-\]]`  matches a caret `^`, hyphen `-`, or closing bracket `]`.
- `\d` matches a digit (equivalent to `[0-9]`),
- `\D` matches anything that is not a digit,
- `\w` matches a word character (equivalent to `[A-Za-z0-9_]` - matches all excluding space, punctuation, symbols and special characters),
- `\W` matches anything that is not a word character,
- `\s` matches a whitespace character (space, tab, newline).
- `\S` matches anything that is not a whitespace.

:::

:::: {.panel-tabset}

## Code

```{webr}
x <- "abcd ABCD 12345 -!@#%."
str_view(x, "\\d+") #<1>
str_view(x, "\\d+") 
str_view(x, "\\D+") 
str_view(x, "\\s+") 
str_view(x, "\\S+") 
str_view(x, "\\w+") 
str_view(x, "\\W+") 
```

#### Hint

```r
x <- "abcd ABCD 12345 -!@#%."
str_view(x, "\\d+") #<1>
str_view(x, "\\D+") #<2>
str_view(x, "\\s+") #<3>
str_view(x, "\\S+") #<4>
str_view(x, "\\w+") #<5>
str_view(x, "\\W+") #<6>
```

1. matches one or more digits
2. matches all that is not digits, one or more times
3. matches one or more whitespace characters
4. matches all that is not whitespace, one or more times
5. matches one or more word characters
6. matches all that is not word characters, one or more times, such as space, newline, tab, punctuation, symbols and special characters.

:::

### Quantifiers: ?, *, +, {}

Quantifiers control how many times a pattern matches.

:::: {.callout-tip title="Quantifiers"}
- `?` matches 0 or 1 time (makes a pattern optional).
- `*` matches 0 or more times.
- `+` matches 1 or more times.
- `{n}` matches exactly n times.
- `{n,}` matches n or more times.
- `{n,m}` matches between n and m times.

:::

### Operator precedence and ()

In regex, **quantifiers have higher precedence** and **alternation has low precedence**: `ab+` is equal to `a(b+)`, while `ab|cd` is equal to `(ab)|(cd)`. Feel free to use parentheses `()` to remeber the precedence rule and override operator precedence for regex.

### Grouping and capturing with ()

Parentheses `()` allow also to create **capturing groups** that allow to use sub-components of the match.

The first way to use capturing group is to refer back to it within a match with **back reference**: `\1`, `\2`, etc. refer to the first, second, etc. parentheses (capturing group).

```r
str_view(fruit, "(..)\\1") #<1>
#> [4] │ b<anan>a          
#>[20] │ <coco>nut         
#>[22] │ <cucu>mber        
#>[41] │ <juju>be          
#>[56] │ <papa>ya          
#>[73] │ s<alal> berry      
```

1. `(..)` captures any two characters; and `\1` refers to the first capturing group, so the pattern matches any two characters followed by the same two characters.

The code below find any word with has same 2 letter at the beginning with `^(..)` and the end of the word by capturing the first back reference `\\1$` . `.*` specifies any characters in between.

```{webr}
str_view(words, "^(..).*\\1$")
#> [152] │ <church>
#> [217] │ <decide>
#> [617] │ <photograph>
#> [699] │ <require>
#> [739] │ <sense>
```

You can use back references in `str_replace()`. The code below switches the order of the second and third words in `sentences`:

```{webr}
sentences |> 
  head(n=5) |> 
  str_replace("(\\w+) (\\w+) (\\w+)", "\\1 \\3 \\2") |> 
  str_view()
```

The matches can be extracted with `str_match()` with the full match and the specific matches; but this returns a matrix, which is not easy to work with. The matrix can be converted to a tibble and name the columns:

```{webr}
sentences |> 
  head(n=7) |> 
  str_match("the (\\w+) (\\w+)") |> 
  as_tibble(.name_repair = "minimal") |> 
  set_names("match", "word1", "word2")
```

This is how `separate_wider_regex()`works behind the scenes. It converts the vector of patterns to a single regex that uses grouping to capture the named components.

When you want to use `()` without creating matching groups, use **non-capturing groups** `(?:)`.

```{webr}
x <- c("a gray cat", "a grey dog")

str_match(x, "gr(e|a)y")

str_match(x, "gr(?:e|a)y")
```

### Exercises

:::: {.panel-tabset}

#### Question 1

How would you match literal string `"'\"`? How about `"$^$"`?

#### Solution

By escaping ' and \. "\\'" and "\\\\"

```{webr}
# Try
```

#### Hint {#hint-2-4-15-1}

```r
x <- c("'\\", "$^$")  #<1>

str_view(x, "(\\'\\\\)|(\\$\\^\\$)") #<2>
```
1. To create `\` in a string, it needs to be escaped with another `\` as it is used to escape other characters. `'` does not need to be escaped within `""`.
2. `\\'` matches literal `'` and `\\\\` matches literal `\`. As string `'` can be created with `"'"` without escaping, even `\'` and `'`without escaping matches literaral `'`. 

:::

:::: {.panel-tabset}

#### Question 2

Explain why each of these patterns don’t match a `\`: `"\"`, `"\\"`, `"\\\"`.

#### Solution

```{webr}
# Try
```

#### Hint

See [Hint under Question 1 of Exercises 2.4.15](#hint-2-4-15-1).

:::

:::: {.panel-tabset}

#### Question 3

Given the corpus of common words in `stringr::words`, create regular expressions that find all words that:

a. Start with “y”.
a. Don’t start with “y”.
a. End with “x”.
a. Are exactly three letters long. (Don’t cheat by using str_length()!)
a. Have seven letters or more.
a. Contain a vowel-consonant pair.
a. Contain at least two vowel-consonant pairs in a row.
a. Only consist of repeated vowel-consonant pairs.

#### Solution

```{webr}
# Try
```

#### Hint

```{webr}
#a.
str_view(words, "^[Yy].*")
#b. 
str_view(words, "[^(Yy)].*")
#c. 
str_view(words, "[A-Za-z]+x$")
str_view(words, ".+x$")
#d. 
str_view(words, "^[A-Za-z]{3}$")
str_view(words, "^(.){3}$")
#e. 
str_view(words, "(.){7,}")
str_view(words, "[A-Za-z]{7,}")
#f. 
str_view(words, "[aeiou]{1}[^aeiou]{1}")
#g. 
str_view(words, "([aeiou]{1}[^aeiou]{1}[aeiou]{1}[^aeiou]{1})+")
#h. 
str_view(words, "(^[aeiou]{1}[^aeiou]{1})+$")
str_view(words, "(^[aeiou]{1}[^aeiou]{1})+$")
```

:::

:::: {.panel-tabset}

#### Question 4

create 11 regular expressions that match the british or american spellings for each of the following words: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. try and make the shortest possible regex!

#### Solution

```{webr}
```

#### Hint

```{webr}
#1.
x <-c("airplane", "aeroplane")
str_view(x, "^a.+e$")
x <-c("aluminum/aluminium")
str_view(x, "^a.+m$" )

#analog/analogue
#ass/arse
#center/centre
#defense/defence
#donut/doughnut
#gray/grey
#modeling/modelling
#skeptic/sceptic
#summarize/summarise
```

:::

:::: {.panel-tabset}

#### Question 5

Switch the first and last letters in words. Which of those strings are still words?

#### Solution

```{webr}
new_words <- head(words, n = 10)
str_replace_all(new_words, "^(.)(.*)(.)$", "\\3\\2\\1")
str_replace_all(new_words, "^(\\w)(.*)(\\w)$", "\\3\\2\\1")
```
:::

:::: {.panel-tabset}

#### Question 6

Describe in words what these regular expressions match: (read carefully to see if each entry is a regular expression or a string that defines a regular expression.)

a. `^.*$`      
a. `"\\{.+\\}"`
a. `\d{4}-\d{2}-\d{2}`
a. `"\\\\{4}"`
a. `\<\.\.\.\>`
a. `(.)\1\1`
a. `"(..)\\1"` 

#### Solution

```{webr}
# Free to tru (see Hint)

```

#### Hint

a. matches any string.
a. matches any sting of 1 or more letters enclosed in {}
a. matches any string of digits composed as a date 4 digits, 2 digits, and 2 digits separated with a dash. looks like a date format `yyy-mm-dd`.
a. matches a string of four backslashes.
a. matches a string of three points enclosed in < >.
a. matches any character repeated three times in a row.
a. matches any two characters repeated twice in a row.

:::

#### Question 7

Solve the beginner regexp crosswords at https://regexcrossword.com/challenges/beginner.

### Pattern control

**Flags** can be used to control the default behavior of regex. In stringr, flags can be used by wrapping the pattern in a call to `regex()`. Some useful flags are:

- `ignore_case = TRUE`: macth both upper- and lowercase

```{r}
bananas <- c("banana", "Banana", "BANANA")
str_view(bananas, "banana")
str_view(bananas, regex("banana", ignore_case = TRUE))
```

- `dotall = TRUE`: lets `.` match everything, incl. `\n`.
```{r}
x <- "Line 1\nLine 2\nLine 3"
str_view(x, ".Line")

str_view(x, regex(".Line", dotall = TRUE))
```

- `multiline = TRUE`: makes `^` and `$` match the start and end of each line rather than the start/end of a string.

```{r}
x <- "Line 1\nLine 2\nLine 3"
str_view(x, "^Line")

str_view(x, regex("^Line", multiline = TRUE))
```

- `comments = TRUE`: tweaks the pattern language to ignore everything after `#`.

```{r}
phone <- regex(
  r"(
    \(?     # optional opening parens
    (\d{3}) # area code
    [)\-]?  # optional closing parens or dash
    \ ?     # optional space
    (\d{3}) # another three numbers
    [\ -]?  # optional space or dash
    (\d{4}) # four more numbers
  )", 
  comments = TRUE
)

str_extract(c("514-791-8141", "(123) 456 7890", "123456"), phone)
```

If you are using comments, to have a space, newlune or #, we need to escape it with  `\`. 

### Fixed matches

`fixed()` can be used instead of `regex()`.

```{r}
str_view(c("", "a", "."), fixed("."))

str_view("x X", "X")

str_view("x X", fixed("X", ignore_case = TRUE))
```

If you are working with non-English languages, use `coll()` instead of `fixed()` as it impliments the full rules for capitalization and `locale`.

```{r}
str_view("i İ ı I", fixed("İ", ignore_case = TRUE))
str_view("i İ ı I", coll("İ", ignore_case = TRUE, locale = "tr"))
```

### Practice

1. Checking your work

```{r}
library(tidyverse)
library(babynames)

# let’s find all sentences that start with “The”. 
str_view(head(sentences), "^The")
# We need to make sure that the “e” is the last letter in the word, which we can do by adding a word boundary:
str_view(sentences, "^The\\b" )

# What about finding all sentences that begin with a pronoun?
str_view(sentences, "^(She\\b|He\\b|We\\b|I\\b|You\\b|They\\b)")
str_view(sentences, "^(She|He|We|I|You|They)\\b")
```

To make sure the regex works and to spot errors, create some positvive and negative matches and test them to test that patterns work as expected:

```{r}
pos <- c("He is a boy", "She had a good time")
neg <- c("Shells come from the sea", "Hadley said 'It's a great day'")

pattern <- "^(She|He|It|They)\\b"
str_detect(pos, pattern)

str_detect(neg, pattern)
```

2. Boolean operations

When you want to find words that only contain consonants, you can create a character class that contains all letters except for the vowels (`[^aeiou]`), then allow that to match any number of letters (`[^aeiou]+`), then force it to match the whole string by anchoring to the beginning and the end (`^[^aeiou]+$`).

```{r}
str_view(words, "^[^aeiou]+$")
```

Another alternative is, instead of matching consonants, one can match words that do not contain vowels.

```{r}
words[!str_detect(words, "[aeiou]")]
```

:::: {.callout-tip title="Important"}

Whenever you are dealing with logical combinations, particularly those involving "and" or "or", or in general when you get stuck trying to create a single regex to solve your problem, **step back and think if you can break the problem into smaller pieces, solving each challenge before moving onto the next one, and combine them in several `str_detect()` calls.

:::

To fin a words that contain "a" and "b", you match words that contain "a" followed by "b" or "b" followed by "a" using `str_view(words, "a.*b|b.*a")` or use a simpler approach of two calls to str_detect() such as `str_detect(words, "a") & str_detect(words, "b")`.

What if we wanted to see if there was a word that contains all vowels? If we did it with patterns we’d need to generate 5! (120) different patterns:

```r
words[str_detect(words, "a.*e.*i.*o.*u")]
# ...
words[str_detect(words, "u.*o.*i.*e.*a")]
```

But it is much simpler to combine five calls to `st_detect()`:

```r
words[
  str_detect(words, "a") &
  str_detect(words, "e") &
  str_detect(words, "i") &
  str_detect(words, "o") &
  str_detect(words, "u")
]
```

3. Creating a pattern with code

If we want to find all `sentences` that mention a color, we can:

```{r}
str_view(sentences, "\\b(red|green|blue)\\b")
```

But writing this gets combersome if is the list of colors is long. We can instead put the colors in a vector vector and use `str_c() or/and `str_flatten()` to create the pattern.

```{r}
rgb <- c("red", "green", "blue")

pattern <- str_c("\\b(", str_flatten(rgb, "|"), ")\\b")
```

Let's we want to use the colors that come with R in `colors()` function.

```r
str_view(colors())

cols <- colors()
cols <- cols[!str_detect(cols, "\\d")] #<1>
pattern <- str_c("\\b(", str_flatten(cols, "|"), ")\\b") #<2>
str_view(sentences, pattern)            #<3>
```

1. exclude color names with digitis.
2. build the pattern
3. apply the pattern and find the match.
   
:::: {.callout-note}

Whenever you create patterns from existing strings, it's wise to run them through `str_escape()` to ensure they match literally.

:::


### Execises

:::: {.panel-tabset}

#### Question 1

For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple `str_detect()` calls.


a. Find all `words` that start or end with `x`.
a. Find all `words` that start with a vowel and end with a consonant.
a. Are there any `words` that contain at least one of each different vowel?

#### Solution

```{r}
#a.
str_view(words, "^x.*|.*x$") 
words[str_detect(words, "^x") | str_detect(words, "x$")]

#b.
str_view(words, "^[aeiou].+[^aeiou]$")
words[str_detect(words, "^[aeiou]") & !str_detect(words, "[aeiou]$")]

#c.
str_view(words, "[aeiou]+")
words[str_detect(words, "[aeiou]")]
```
:::


:::: {.panel-tabset}

#### Question 2

Construct patterns to find evidence for and against the rule “i before e except after c”?

:::

:::: {.panel-tabset}

#### Question 3

 `colors()` contains a number of modifiers like “lightgray” and “darkblue”. How could you automatically identify these modifiers? (Think about how you might detect and then remove the colors that are modified).

#### Solution

```{r}
colrs <- colors()
colrs[!str_detect(colrs, "\\d")]
rgb <- c("red" , "green ", "blue")
pattern <- str_c("(\\d+$)|", "(\\w+)(", str_flatten(rgb, "|"), ")", "(\\w*)")
pattern
colrs[str_detect(colrs, pattern)]
colrs[!str_detect(colrs, pattern)]
```

:::

:::: {.panel-tabset}

#### Question 4

Create a regular expression that finds any base R dataset. You can get a list of these datasets via a special use of the `data()` function: `data(package = "datasets")$results[, "Item"]`. Note that a number of old datasets are individual vectors; these contain the name of the grouping “data frame” in parentheses, so you’ll need to strip those off.

#### Solution

```{r}
library(tidyverse)
library(babynames)
data()
```

:::

## Factors

In addition to base R, we till use the `{forcats}` package in the core tidyverse.

```{webr}
library(tidyverse)
library(forcats)
```

### Basics

```{webr}
x1 <- c("Dec", "Apr", "Jan", "Mar")
x2 <- c("Dec", "Apr", "Jam", "Mar")
sort(x1) # sorts alphabetically, not by months. To solve this use levels() function.

month_levels <- c(
  # create of levels.
  "Jan",
  "Feb",
  "Mar",
  "Apr",
  "May",
  "Jun",
  "Jul",
  "Aug",
  "Sep",
  "Oct",
  "Nov",
  "Dec"
)
(y1 <- factor(x1, levels = month_levels)) # create factor
sort(y1) # Now, sorting works after using levels and any values not in the levels will be silently converted to NA

y2 <- factor(x2, levels = month_levels)
y2 # "Jam" is converted to NA because it is in the factors but not in the levels.
sort(y2)

y3 <- factor(c(1, 2), labels = c("Yes", "No"))
y3
str(y3)

levels(y3) # to access the levels of a factor.
```

`factor()` converts missing levels to NA without a warning, which is risky. 

`forcats::fct()` warns if there is a value missing in the levels: whithout setting levels(), forcats::ftc() orders the levels by appearance. 

```{webr}
#| eval: false
y2 <- forcats::fct(x2, levels = month_levels)
# y2
#
# Error in `forcats::fct()`:
# ! All values of `x` must appear in `levels` or `na`
# ℹ Missing level: "Jam"
# Backtrace:
#  1. forcats::fct(x2, levels = month_levels)
# Error in forcats::fct(x2, levels = month_levels) :
# ℹ Missing level: "Jam"

y4 <- fct(c("0", "1"), levels = c("1"), na = "0")
y4
```


If you omit the levels, `factor()` will take them in alphabetical order, but `forcats::fct()` will order by appearance.

```{webr}
factor(x1) # orders alphabetically.
fct(x1) # orders by appearance.
```
You can also create a factor when reading your data with `{webreadr}` with `col_factor()`:

```{webr}
csv <- "
month, value
Jan, 12
Feb, 56
Mar, 12
"

df <- read_csv(csv, col_types = cols(month = col_factor(month_levels)))
df$month
sort(df$month)
```

### General Social Survey (GSS)

`forcats::gss_cat` is a sample of data from the GSS, a long-running US survey conducted by the National Opinion Research Center (NORC) at the University of Chicago.

```{webr}
forcats::gss_cat
```

When factors are stores in a tibble, their levels are not easily visible. `count()`.

```{webr}
gss_cat |>
  count(race)
```

#### Exercises

1. Explore the distribution of `rincome` (reported income). What makes the default bar chart hard to understand? How could you improve the plot?

```{webr}

```

2. What is the most common `relig` in this survey? What’s the most common `partyid``
`
```{webr}

```

3. Which `relig` does denom (denomination) apply to? How can you find out with a table? How can you find out with a visualization?

```{webr}

```

### Modify factor order: fct_reorder() and fct_relevel()

This plot presenting the average number of hours spent watching TV by religion (affiliation) is hard to read because the number of hours is not increasing or decreasing.
 
```{webr}
relig_summary <- gss_cat |>
  group_by(relig) |>
  summarize(
    tvhours = mean(tvhours, na.rm = TRUE),
    n = n()
  )

ggplot(relig_summary, aes(x = tvhours, y = relig)) +
  geom_point()
```

We may want to modify this plot by changing the order of the levels: We can use `fct_reorder()` and `fct_relevel()`.

`fct_reorder()` takes three arguments: 
1. `.f`, the factor whose levels you want to modify. 
2. `.x`, a numeric vector that you want to use to reorder the levels. 
3. Optionally, `.fun`, a function that’s used if there are multiple values of `.x` for each value of `.f`. The default value is median.

```{webr}

ggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) + #reorder relig by increasing/decreasing tvhours
  geom_point()
```

The factor-reordering can be done with `mutate()` before ggplot.

```{webr}
relig_summary |>
  mutate(
    relig = fct_reorder(relig, tvhours, .desc = TRUE) # default is ascending (.desc = FALSE), .desc = TRUE is descending
  ) |>
  ggplot(aes(x = tvhours, y = relig)) +
  geom_point()
```

Plot how average age varies by income bracket:

```{webr}
rincome_summary <- gss_cat |>
  group_by(rincome) |>
  summarize(
    age = mean(age, na.rm = TRUE),
    n = n()
  )

ggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age))) +
  geom_point()
```

`fct_reorder()` is suited for factors with arbitrary order. When factors have a natural ordering, and you want to pull to the front one level, use
`fct_relevel()`. It takes as arguments the factor, `.f`, and then any number of levels that you want to move to the front of the line.

```{webr}
ggplot(
  rincome_summary,
  aes(x = age, y = fct_relevel(rincome, "Not applicable"))
) +
  geom_point()
```

```{webr}
ggplot(
  rincome_summary,
  aes(x = age, y = fct_relevel(rincome, c("Not applicable", "Lt $1000")))
) +
  geom_point()
```

Another type of reordering is useful when you are coloring the lines on a plot. fct_reorder2(.f, .x, .y) reorders the factor .f by the .y values associated with the largest .x values. This makes the plot easier to read because the colors of the line at the far right of the plot will line up with the legend.

```{webr}
by_age <- gss_cat |>
  filter(!is.na(age)) |>
  count(age, marital) |>
  group_by(age) |>
  mutate(
    prop = n / sum(n)
  )

ggplot(by_age, aes(x = age, y = prop, color = marital)) +
  geom_line(linewidth = 1) +
  scale_color_brewer(palette = "Set1")

ggplot(
  by_age,
  aes(x = age, y = prop, color = fct_reorder2(marital, age, prop))
) + # reorder marital status by age and associated proportion.
  geom_line(linewidth = 1) +
  scale_color_brewer(palette = "Set1") +
  labs(color = "marital")
```


In bar plots, use `fct_infreq()` to show order in decreasing frequency: it can be combined with `fct_rev()` to show order in increasing frequency.

```{webr}
gss_cat |>
  mutate(marital = marital |> fct_infreq() |> fct_rev()) |> #this is the simplest type of reordering because it doesn’t need any extra variables.
  ggplot(aes(x = marital)) +
  geom_bar()
```

#### Exercises

1. There are some suspiciously high numbers in tvhours. Is the mean a good summary?
1. For each factor in gss_cat identify whether the order of the levels is arbitrary or principled.
1. Why did moving “Not applicable” to the front of the levels move it to the bottom of the plot?

### Modify values of factor levels: `fct_recode()`

`fct_recode()` takes as argument `.f` factor, and the levels to recode/rename with "new levels" on the left = "old levels" on the right. It leaves unchanged levels that are not mentioned and warn if your refer to that do not exist as "old levels".

```{webr}
gss_cat |> count(partyid)
```

```{webr}
gss_cat |>
  mutate(
    partyid = fct_recode(
      partyid,
      "Republican, strong" = "Strong republican",
      "Republican, weak" = "Not str republican",
      "Independent, near rep" = "Ind,near rep",
      "Independent, near dem" = "Ind,near dem",
      "Democrat, weak" = "Not str democrat",
      "Democrat, strong" = "Strong democrat"
    )
  ) |>
  count(partyid)
```

To combine groups, you can assign multiple old levels to the same new level.

If you want to collapse a lot of levels, `fct_collapse()` is a useful variant of `fct_recode()`. For each new variable, you can provide a vector of old levels:

```{webr}
gss_cat |>
  mutate(
    partyid = fct_collapse(
      partyid,
      "other" = c("No answer", "Don't know", "Other party"),
      "rep" = c("Strong republican", "Not str republican"),
      "ind" = c("Ind,near rep", "Independent", "Ind,near dem"),
      "dem" = c("Not str democrat", "Strong democrat")
    )
  ) |>
  count(partyid)
```

Sometimes, one may want to lump small groups together: this can be chieved with `fct_lump_*()` family of functions.

`fct_lump_lowfreq()`lumps the smallest groups into "Other" category, keeping "Other" always the smallest category. 

```{webr}
gss_cat |>
  mutate(relig = fct_lump_lowfreq(relig)) |>
  count(relig)
```

`fct_lump_lowfreq()`can lump groups in a less useful way: `fct_lump_n()` `can` be `used` to `specify` the exact number of categories you want to keep.

```{webr}
gss_cat |>
  mutate(relig = fct_lump_n(relig, n = 10)) |>
  count(relig, sort = TRUE)
```

See also `fct_lump_min()` and `fct_lump_prop()`.

#### Exercises

1. How have the proportions of people identifying as Democrat, Republican, and Independent changed over time?
2. How could you collapse rincome into a small set of categories?
3. Notice there are 9 groups (excluding other) in the `fct_lump` example above. Why not 10? (Hint: type `?fct_lump`, and find the default for the argument `other_level` is “Other”.)

### Ordered factors: `ordered()`

Created with the ordered() function, ordered factors imply a strict ordering between levels, but don’t specify anything about the magnitude of the differences between the levels. You use ordered factors when you know there the levels are ranked, but there’s no precise numerical ranking.

Ordered factors uses `<`symbols between levels when it is printed.

```{webr}
ordered(c("a", "b", "c"))
```

In both base R and the tidyverse, ordered factors behave very similarly to regular factors. There are only two places where you might notice different behavior:

- If you map an ordered factor to color or fill in ggplot2, it will default to scale_color_viridis()/scale_fill_viridis(), a color scale that implies a ranking.
- If you use an ordered predictor in a linear model, it will use “polynomial contrasts”. These are mildly useful, but you are unlikely to have heard of them unless you have a PhD in Statistics, and even then you probably don’t routinely interpret them. If you want to learn more, we recommend vignette("contrasts", package = "faux") by Lisa DeBruine.

## Dates and times

```{webr}
library(tidyverse)
library(nyflights13)
```

:::: {.callout-note title="Aims"}

- To teach to create date-times from various inputs.
- To teach how to extract date-times components.
- To work with time spans.
- How to work with time zomes.

:::

This section willl use the`{lubridate}` package and `nyflights13` dataset in tydiverse package.

### Creating date/times

Three types of date/time data:
- date: tibbles prnt `<date>`
- time within a day: tibbles print `<time>`
- date-time (a date plus a time): identifies an instant in time typically to the nearest second. Tibbles print `<dttm>`. Base R calls thes POSIXct.

R does not have a native class for storing times: use {hms} package if need be.

:::: {.callout-tip}

Use the simplest date type the works for you needs. Date-times are more complicated because they need to handle time zones: Use a date instead if enough for your needs!

:::

```{r}
library(tidyverse)
library(nycflights13)
library(gt)
today() # current date
now() # current date-time
```

Four ways to create a date/time:
- when reading in a file with `{readr}`
- from a string
- from individual date-time components
- from an existing date/time object
  
#### During import

If your CSV file contains an **ISO8601**, readr will recognize it.

:::: {.callout-note title="ISO8601"}

ISO8601 is an international standard for writing dates where the components are organised from biggest to smallest (year to day) separated by `-`. ISO8601 can includes hour, minute, and second separated by `:`; and date and time components are separated with a `T` or a space.

For example, 4:326pm on May 2 2022 is `2022-05-03 16:26` or `2022-05-03T1626`.

:::

For other date/time formats not in ISO8601, use `col_types()` plus `col_date()` or `col_datetime()`. @tbl-date-time-format-readr shows date formats understood by readr.


```{r}
#| label: tbl-date-time-format-readr
#| tbl-cap: "Date formats understood by readr"
#| echo: false

date_formats <- tribble(
  ~Type,    ~code,                  ~example,           ~description,
  "Year",   "`%Y-%m-%d`",             "2010-01-01",       "Year-month-day (ISO 8601)",
  "Year",   "`%Y/%m/%d`",             "2010/01/01",       "Year/month/day",
  "Year",   "`%Y%m%d`",               "20100101",         "Compact year-month-day",
  "Year",   "`%y-%m-%d`",             "10-01-01",         "Two-digit year",
  "Year",   "`%m/%d/%Y`",             "01/31/2010",       "US style: month/day/year",
  "Year",   "`%m-%d-%Y`",             "01-31-2010",       "US style with dashes",
  "Year",   "`%d/%m/%Y`",             "31/01/2010",       "European style: day/month/year",
  "Year",   "`%d-%m-%Y`",             "31-01-2010",       "European style with dashes",
  "Year",   "`%d %b %Y`",             "01 Jan 2010",      "Day abbreviated-month year",
  "Year",   "`%d %B %Y`",             "01 January 2010",  "Day full-month year",
  "Year",   "`%b %d, %Y`",            "Jan 01, 2010",     "Abbrev-month day, year",
  "Year",   "`%B %d, %Y`",            "January 01, 2010", "Full-month day, year",
  "Year",   "`%d.%m.%Y`",             "31.01.2010",       "Dot-separated day.month.year",
  "Year",   "`%e %b %Y`",             " 1 Jan 2010",      "Day with leading space allowed",
  "Year",   "`%Y-%j`",                "2010-032",         "Year and day of year (Julian day)",
  "Time",   "`%H:%M:%S`",             "16:26:00",         "24-hour time with seconds",
  "Time",   "`%H:%M`",                "16:26",            "24-hour time without seconds",
  "Time",   "`%I:%M %p`",             "04:26 PM",         "12-hour time with AM/PM",
  "Time",   "`%H%M`",                 "1626",             "Compact 24-hour time (no colon)",
  "Time",   "`%T`",                   "16:26:00",         "Alias for %H:%M:%S",
  "Time",   "`%R`",                   "16:26",            "Alias for %H:%M",
  "Time",   "`%S`",                   "00",               "Second (00–59)",
  "Time",   "`%H`",                   "16",               "Hour (00–23)",
  "Time",   "`%I`",                   "04",               "Hour (01–12)",
  "Time",   "`%p`",                   "PM",               "AM/PM indicator",
  "Time",   "`%z`",                   "+0200",            "Timezone offset from UTC",
  "Time",   "`%Z`",                   "CEST",             "Timezone abbreviation",
  "Other",  "`%.`",                   "Skip one digit",   ":",
  "Other",  "%*",                     "Skip any number of non-digits",  "",
)

date_formats |>
  select(Type, code, description, example) |> 
  group_by(Type) |> 
  gt() 
```

## Mssing values


## Joins